{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Competition - Santander**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict # for the data, we don't want to have to create a new array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just flushing out buffer asap.\n",
    "import sys\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "train_data = defaultdict(list)\n",
    "test_data = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(name):\n",
    "    '''\n",
    "    Params: name of file\n",
    "    returns: tuple [keys from the first line of csv file, rest of the lines as arr]\n",
    "    '''\n",
    "    data_keys = []\n",
    "    raw_data = []\n",
    "    # Reading in the keys of the value\n",
    "    with open(name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for k in lines[0].split(\",\"):\n",
    "            data_keys.append(k)\n",
    "        raw_data = lines[1:]\n",
    "    return [data_keys, raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingest_data(data_keys, data_arr, result, flags, flag_replace):\n",
    "    '''\n",
    "    Params: keys from first line, data from the rest of lines, result in the form of a dict(defaultdict allowed)\n",
    "    returns: 2D ndarray\n",
    "    '''\n",
    "    # Taking in the data using the keys\n",
    "    arr_out = []\n",
    "    for row in data_arr:\n",
    "        arr_in = []\n",
    "        for key, dat in zip(data_keys, row.split(\",\")):\n",
    "            num = float(dat)\n",
    "            if dat in flags:\n",
    "                result[key].append(flag_replace)\n",
    "                arr_in.append(flag_replace)\n",
    "            else:\n",
    "                result[key].append(num)\n",
    "                arr_in.append(num)\n",
    "        arr_out.append(arr_in)\n",
    "    return np.array(arr_out, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_key, raw_train_data = read_file('train.csv')\n",
    "test_key, raw_test_data = read_file('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = ingest_data(train_key, raw_train_data, train_data, [\"9999999999\", \"-999999\"], -1)\n",
    "# test_data = ingest_data(test_key, raw_test_data, test_data) Remove this line temporarily for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76020\n",
      "0\n",
      "(76020, 371)\n"
     ]
    }
   ],
   "source": [
    "# Test to see the size of train_data\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 337)\n"
     ]
    }
   ],
   "source": [
    "# Prune the zeros\n",
    "columns_removed = np.all(train_data == 0, axis=0)\n",
    "train_data = train_data[:,~columns_removed]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 336)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# split the values into X and y\n",
    "train_X = train_data[:,:-1]\n",
    "train_y = train_data[:,-1]\n",
    "print(train_X.shape)\n",
    "print(train_y[:50]) # Okay we have at least 1 here, sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 100)\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "train_X -= np.mean(train_X, axis=0)\n",
    "train_X /= np.std(train_X, axis=0)\n",
    "cov = np.dot(train_X.T, train_X)/train_X.shape[0]\n",
    "U,S,V = np.linalg.svd(cov)\n",
    "train_X_reduced = np.dot(train_X, U[:,:100])\n",
    "print(train_X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=76020, n_folds=4, shuffle=False, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# Create CV test set\n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(train_X_reduced.shape[0], n_folds=4)\n",
    "len(kf)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 11 line NN\n",
    "\n",
    "def sigmoid(x, syn):\n",
    "    return 1/(1+np.exp(-(np.dot(x, syn)/1000)))\n",
    "\n",
    "def forward(syn0, syn1, X):\n",
    "    l1 = sigmoid(X, syn0)\n",
    "    l2 = sigmoid(l1, syn1)\n",
    "    return [l1, l2]\n",
    "\n",
    "def train_iter(X, y, verbose = True):\n",
    "    syn0 = 2*np.random.random((X.shape[1], 200))-1\n",
    "    syn1 = 2*np.random.random((200,1))-1\n",
    "    for j in range(100):\n",
    "        l1, l2 = forward(syn0, syn1, X)\n",
    "        l2_delta = (y.reshape(-1,1)-l2)*(l2*(1-l2))\n",
    "        l1_delta = l2_delta.dot(syn1.T)*(l1*(1-l1))\n",
    "        syn1 += l1.T.dot(l2_delta)*0.01\n",
    "        syn0 += X.T.dot(l1_delta)*0.01\n",
    "        cost = -np.sum(np.log(l2)*y.reshape(-1, 1) + np.log(1-l2)*(1-y.reshape(-1, 1)))\n",
    "        if verbose:\n",
    "            print(\"Epoch count : \" + str(j))\n",
    "            print(\"Cost : \" + str(cost))\n",
    "    return [syn0, syn1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(syn0, syn1, X, y):\n",
    "    # try to predict using this naÃ¯ve approach\n",
    "    _, ans = forward(syn0, syn1, X)\n",
    "    # turn ans into binary vector\n",
    "    ans = ans > 0.25\n",
    "    return [ans, np.sum(ans == y.reshape(-1, 1))/y.shape[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [12500 12501 12502 ..., 49997 49998 49999] TEST: [    0     1     2 ..., 12497 12498 12499]\n",
      "The # of 1's : 6 and acc : 0.9608\n",
      "TRAIN: [    0     1     2 ..., 49997 49998 49999] TEST: [12500 12501 12502 ..., 24997 24998 24999]\n",
      "The # of 1's : 14 and acc : 0.9564\n",
      "TRAIN: [    0     1     2 ..., 49997 49998 49999] TEST: [25000 25001 25002 ..., 37497 37498 37499]\n",
      "The # of 1's : 21 and acc : 0.964\n",
      "TRAIN: [    0     1     2 ..., 37497 37498 37499] TEST: [37500 37501 37502 ..., 49997 49998 49999]\n",
      "The # of 1's : 16 and acc : 0.9616\n"
     ]
    }
   ],
   "source": [
    "X = train_X_reduced[:50000,:] #500 batch\n",
    "y = train_y[:50000].reshape(-1, 1)\n",
    "kf = KFold(X.shape[0], n_folds=4)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    syn0, syn1 = train_iter(X_train, y_train, False)\n",
    "    ans, acc = predict(syn0, syn1, X_test, y_test)\n",
    "    print(\"The # of 1's : \" + str(np.sum(ans)) + \" and acc : \" + str(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
